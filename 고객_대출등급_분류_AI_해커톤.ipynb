{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smpark0520/ESAA/blob/main/%EA%B3%A0%EA%B0%9D_%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89_%EB%B6%84%EB%A5%98_AI_%ED%95%B4%EC%BB%A4%ED%86%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Info.\n",
        "\n",
        "train.csv [파일]\n",
        "고객 관련 금융 정보\n",
        "ID : 대출 고객의 고유 ID\n",
        "대출등급 : 예측 목표\n",
        "\n",
        "\n",
        "test.csv [파일]\n",
        "고객 관련 금융 정보\n",
        "ID : 대출 고객의 고유 ID\n",
        "대출등급이 존재하지 않음\n",
        "\n",
        "\n",
        "sample_submission.csv [파일] - 제출 양식\n",
        "ID : 대출 고객의 고유 ID\n",
        "대출등급 : test.csv에서 제공된 고객의 대출등급을 예측하여 기입"
      ],
      "metadata": {
        "id": "n9Gm4sfOuxVm"
      },
      "id": "n9Gm4sfOuxVm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 파생변수 생성\n",
        "- EDA를 통해 '총상환원금', '총상환이자'가 주요한 영향을 미치는 것을 파악했고, 두 변수의 결합('총상환원금'/'총상환이자')으로 파생변수를 생성했습니다.\n",
        "- 신용점수 평가 기준을 찾아보니 상환능력이 중요한 것 같더군요. 따라서, '총상환원금'/'대출금액'으로 '상환비율' 변수를 생성했습니다.\n",
        "- 두 변수 생성 이후, 0.83에서 0.951로 점수가 가장 큰 폭으로 상승했습니다.\n",
        "\n",
        "2.  변수 제거 (RFECV, Feature Importance)\n",
        "- Feature Importance를 찍어보니 값이 0에 가까운 변수들이 몇 개 있어서 아예 제거하기로 했습니다.\n",
        "- 변수 선택법인 RFECV를 활용, 변수를 3개로 줄였습니다. ('대출기간', '총상환원금/총상환이자', '상환비율')\n",
        "- 이 방법으로 0.02 정도 점수가 오른 것 같습니다.\n",
        "\n",
        "3. 하이퍼파라미터 튜닝 (Optuna)\n",
        "- 튜닝 전, 성능이 괜찮게 나왔던 ET, RF, DT, XGB 총 4가지 모델들에 대해 튜닝을 진행했습니다.\n",
        "- XGB의 경우 tree_method에 따라 점수가 많이 달라지는 것을 확인해 튜닝 작업에 추가했습니다.\n",
        "- 튜닝 이후, 0.951에서 0.953으로 점수가 상승했습니다.\n",
        "\n",
        "4. 앙상블 모델 (Stacking)\n",
        "- Voting과 Stacking, 그리고 여러 모델끼리 조합을 해보면서 가장 성능이 좋은 조합을 찾아갔습니다.\n",
        "- Stacking(ET+XGB+DT+RF)을 사용한 결과, 0.953에서 0.955로 점수가 증가해 최종 모델로 선정했습니다.v"
      ],
      "metadata": {
        "id": "ZQCEr6ABuzPc"
      },
      "id": "ZQCEr6ABuzPc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b133cced",
      "metadata": {
        "id": "b133cced"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "seed_everything()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705fb661",
      "metadata": {
        "id": "705fb661"
      },
      "outputs": [],
      "source": [
        "train_raw = pd.read_csv('train.csv')\n",
        "test_raw = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aedebac5",
      "metadata": {
        "id": "aedebac5"
      },
      "outputs": [],
      "source": [
        "def preprocess(train, test):\n",
        "\n",
        "    ############################################### train 전처리 ###############################################\n",
        "    train = train.drop(columns = ['ID'])\n",
        "    train['대출기간'] = train['대출기간'].str.replace('[^0-9]','')\n",
        "    train['대출기간'] = (train['대출기간'].astype(int))//12\n",
        "\n",
        "    # 범주형 변수 인코딩\n",
        "    le = LabelEncoder()\n",
        "    train['대출등급'] = le.fit_transform(train['대출등급'])\n",
        "\n",
        "    # 파생변수\n",
        "    train['총상환원금/총상환이자'] = (train['총상환원금'])/(train['총상환이자']+1)\n",
        "    train['상환비율'] = train['총상환원금'] / train['대출금액']\n",
        "\n",
        "\n",
        "    ############################################### test 전처리 ###############################################\n",
        "    test = test.drop(columns = ['ID'])\n",
        "    test['대출기간'] = test['대출기간'].str.replace('[^0-9]','')\n",
        "    test['대출기간'] = (test['대출기간'].astype(int))//12\n",
        "\n",
        "    # 파생변수\n",
        "    test['총상환원금/총상환이자'] = (test['총상환원금'])/(test['총상환이자']+1)\n",
        "    test['상환비율'] = test['총상환원금'] / test['대출금액']\n",
        "\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a077d41c",
      "metadata": {
        "id": "a077d41c"
      },
      "outputs": [],
      "source": [
        "train,test = preprocess(train_raw, test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1679b03",
      "metadata": {
        "id": "c1679b03"
      },
      "outputs": [],
      "source": [
        "X = train[['대출기간','총상환원금/총상환이자','상환비율']]; y = train['대출등급']\n",
        "test = test[['대출기간','총상환원금/총상환이자','상환비율']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5469db11",
      "metadata": {
        "id": "5469db11"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state = 42\n",
        "                         , n_estimators = 305\n",
        "                         , criterion = 'gini'\n",
        "                         , max_depth = 62\n",
        "                         , min_samples_split = 7\n",
        "                         , min_samples_leaf = 1)\n",
        "dt = DecisionTreeClassifier(random_state = 42\n",
        "                         , criterion = 'entropy'\n",
        "                         , max_depth = 25\n",
        "                         , min_samples_split = 2\n",
        "                         , min_samples_leaf = 1)\n",
        "et = ExtraTreesClassifier(random_state = 42\n",
        "                         , n_estimators = 930\n",
        "                         , criterion = 'entropy'\n",
        "                         , max_depth = 65\n",
        "                         , min_samples_split = 6\n",
        "                         , min_samples_leaf = 1\n",
        "                         )\n",
        "xgb = XGBClassifier(random_state = 42\n",
        "                   , n_estimators = 665\n",
        "                   , reg_lambda = 0.04614513317156364\n",
        "                   , reg_alpha = 0.8831857977740336\n",
        "                   , tree_method = \"exact\"\n",
        "                   , colsample_bytree = 0.7664006730032823\n",
        "                   , subsample = 0.6579847353498132\n",
        "                   , learning_rate = 0.4046062291148477\n",
        "                   , max_depth = 64\n",
        "                   , min_child_weight = 2\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b648eb1d",
      "metadata": {
        "id": "b648eb1d"
      },
      "outputs": [],
      "source": [
        "scale = StandardScaler()\n",
        "X = scale.fit_transform(X)\n",
        "test = scale.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d7f0c7",
      "metadata": {
        "id": "e3d7f0c7",
        "outputId": "9a11c3a8-399c-4cf9-fae8-61aa6917e2ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.3min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.7min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.9min finished\n"
          ]
        }
      ],
      "source": [
        "estimators = [('et',et), ('xgb',xgb), ('dt',dt), ('rf',rf)]\n",
        "stack = StackingClassifier(estimators, final_estimator=LogisticRegression(), verbose=1)\n",
        "stack.fit(X,y)\n",
        "pred = stack.predict(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6376af17",
      "metadata": {
        "id": "6376af17",
        "outputId": "37e5cc35-3095-4b4a-9cb3-1ec7fd668d10"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>대출등급</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_00000</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_00001</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_00002</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_00003</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_00004</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID 대출등급\n",
              "0  TEST_00000    B\n",
              "1  TEST_00001    B\n",
              "2  TEST_00002    A\n",
              "3  TEST_00003    C\n",
              "4  TEST_00004    C"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['대출등급'] = pred\n",
        "sub['대출등급'] = sub['대출등급'].map({0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G'})\n",
        "sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe39aa29",
      "metadata": {
        "id": "fe39aa29"
      },
      "outputs": [],
      "source": [
        "sub.to_csv('final_submission.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<배울 점>\n",
        "- Optuna 라이브러리 이용한 점\n",
        "- 두 변수의 결합('총상환원금'/'총상환이자')으로 파생변수를 생성했다는 점"
      ],
      "metadata": {
        "id": "itcqilWYvJme"
      },
      "id": "itcqilWYvJme"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}